# This is an example of a graderutils configuration file that you use to control test execution and result parsing.
# Test configs are merged with baseconfig.yaml
# This file is very verbose on purpose, ../examples/01_simple/test_config.yaml contains a minimal example.
# The only required key in a test config yaml is the list of Python module names that should be executed as tests, everything else is optional


# List of test groups, i.e. definitions of Python modules containing at least one unittest.TestCase.
# At least one must be specified.
# Modules are executed in the same order as they have been specified in this list.
test_groups:
    # The module key should contain the name of an importable Python module which contains at least one unittest.TestCase class.
    - module: local_tests
      display_name: Local tests
      description: Tests that were distributed with the exercise template
    # You can use an arbitrary amount of modules to group tests of different characteristics
    - module: grader_tests
      display_name: Grader tests
      description: Tests that were distributed with the exercise template
    - module: compile_tests
      display_name: Compilation tests
      description: Tests for checking that the submitted source code compiles on multiple platforms

# (Optional)
# Paths to custom Jinja2 HTML templates that extend or replace the default template at graderutils_format/templates/feedback.html
feedback_template: my_feedback_template.html

# (Optional)
# Set an integer value in seconds for how long each test method is allowed to run until timing out.
# Measured with time.perf_counter and includes time spent sleeping.
# Defaults to 60 seconds if not specified.
testmethod_timeout: 10

# Optional input validation before running test groups.
# Successful validation is silent, i.e. if all validation tasks pass, no output is generated from the validation.
# If at least one validation task fails, no test groups will be run, and instead the validation errors will be shown.
validation:
    # Failed validation tasks are shown as a test group with a default display_name "Input validation"
    display_name: Input validation
    tasks:
        # Try importing my_solution as a Python module, catch all exceptions and pass them to the error template.
        - type: python_import
          # Name of this validation task, e.g. formulated as an assertion like in a test method
          display_name: "The file is a Python module that can be imported"
          file: my_solution.py
        # Set restricted syntax which should not be found in file.
        # If such syntax is found, pass data of found matches to the error template.
        - type: python_blacklist
          display_name: "Module does not contain restricted syntax"
          description: "In this exercise, some builtin syntax related to lists is not allowed, since you should make you own list implementation."
          file: my_solution.py
          # By default, if a validation task fails, validation is stopped and feedback is shown for the failed task.
          # If break_on_fail is given and False, and this validation task fails,
          # the failed validation result is appended into a list and the next task will run as if this one passed.
          break_on_fail: False
          # Names of abstract syntax tree nodes and custom messages which are shown if nodes are found in the submitted file.
          # A comprehensive list of AST nodes can be found here: https://greentreesnakes.readthedocs.io/en/latest/nodes.html
          node_names:
              ListComp: List comprehensions
              For: For loops
              # Optionally, define exact strings returned by ast.dump, which are not allowed.
              # The graderutils.validation module contains a simple ast_dump function for dumping all ast nodes of a given source string.
          node_dumps:
              "Name(id='list', ctx=Load())": Loading the list builtin
          # If a full ast.dump string match is too specific, it can be 'softened' using regexp.
          # You have to do escaping by yourself, though.
          node_dump_regexp:
              "^Attribute.*attr\\=\\'sort\\'\\,\\ ctx\\=Load\\(\\)": Loading the sort method
        # Simple regexp-based substring blacklisting.
        - type: plain_text_blacklist
          display_name: "Module does not contain restricted syntax"
          description: "The solution contains restricted keywords"
          file: my_solution.sql
          # If ignorecase is True, all keys in strings dict must be in lowercase
          ignorecase: True
          strings:
              drop: Dropping tables
              delete: Deleting entries

        # More validation options

        # Whitelists are inverted blacklists, where all node names and node dumps are restricted, unless specified in the whitelist.
        # There are no exceptions, if the node is not in included in the whitelist and it is in the submitted module, it will not be accepted.
        # The messages in node_names and node_dumps are ignored, but you can provide a message in 'message'.
        - type: python_whitelist
          display_name: "Module does not contain restricted syntax"
          description: "You should only submit closed form equations, other kind of syntax is not allowed in this exercise."
          file: my_solution.py
          node_names:
              # Node messages are ignored for whitelists and the name of the missed node will be used instead.
              Module: Module
              Assign: Assigning values to names
              # Storing and loading names/variables
              Name: Using names
              Load: Loading a name
              Store: Storing a name
              # Bitwise operations and matrix multiplication are not included
              BinOp: Binary operations
              Add: Addition
              Sub: Subtraction
              Mult: Multiplication
              Div: Division
              FloorDiv: Floor division
              Mod: Modulo
              Pow: Power

# Optional traceback hiding
# If an exception with a given class_name is raised, its traceback is removed from the output, leaving only the exception line.

# e.g. with AssertionError:
#
# Traceback (most recent call last):
#   File "local_tests.py", line 33, in test_is_prime_with_no_primes
#    "{:d} is not a prime number, but your function says it is".format(value)
# AssertionError: True is not false : -1 is not a prime number, but your function says it is
#
# only the following will be displayed:
#
# AssertionError: True is not false : -1 is not a prime number, but your function says it is
#
# If remove_sentinel is given, then all traceback until (including) the sentinel string, will be removed.
#
# e.g. with AssertionError and remove_sentinel [remove-stop]:
#
# Traceback (most recent call last):
#   File "local_tests.py", line 33, in test_is_prime_with_no_primes
#    "{:d} is not a prime number, but your function says it is".format(value)
# AssertionError: True is not false : [remove-stop]-1 is not a prime number, but your function says it is
#
# turns into just:
#
# -1 is not a prime number, but your function says it is
#

format_tracebacks:
    # Hide tracebacks raised from IndexError
    # Hiding is done by regexp substitution from the traceback string, so this needs to be an exact character match
    - class_name: IndexError
      hide_tracebacks: true
      # Replace hidden strings with this
      hide_tracebacks_replacement: "## hidden IndexError ##"
      # Hide tracebacks only from the main test result panel, i.e. let them be visible in the full traceback panels that can be opened with a button
      hide_tracebacks_short_only: true
    # Using a sentinel to remove the messages inserted by unittest.TestCase
    - class_name: AssertionError
      hide_tracebacks: true
      hide_tracebacks_short_only: true
      # Remove tracebacks until (including) this sentinel string
      remove_sentinel: "[remove-stop]"
    # Default configuration, hide all tracebacks
    - class_name: '*'
      hide_tracebacks: true
      hide_tracebacks_short_only: true
